#include "nexus/transport/SharedMemoryTransportV3.h"
#include "nexus/core/NodeImpl.h"  // For handleNodeEvent callback
#include "nexus/utils/Logger.h"
#include <sys/mman.h>
#include <sys/stat.h>
#include <sys/epoll.h>  // ğŸ”§ epollæ”¯æŒï¼ˆFIFOæ¨¡å¼ï¼‰
#include <fcntl.h>
#include <unistd.h>
#include <pthread.h>   // ğŸ”§ POSIXçº¿ç¨‹æ”¯æŒï¼ˆCondition Variableï¼‰
#include <cstring>
#include <cerrno>     // For errno
#include <chrono>
#include <iostream>
#include <sstream>
#include <iomanip>
#include <dirent.h>
#include <signal.h>   // For kill() process detection
#include <sstream>    // For std::ostringstream

// QNX specific includes
#ifdef __QNXNTO__
#include <sys/neutrino.h>
#include <sys/procfs.h>
#endif

// ============ SharedMemoryTransportV3 Constants ============
// Flow control and congestion management
#define SHM_BACKOFF_BASE_US 10              // Congestion backoff base (microseconds)
#define SHM_BACKOFF_MAX_US 1000             // Congestion backoff maximum
#define SHM_CONGESTION_INCREMENT 5          // Congestion level increment on failure
#define SHM_CONGESTION_DECREMENT 1          // Congestion level decrement on success
#define SHM_CONGESTION_MAX 100              // Maximum congestion level
#define SHM_CONGESTION_INITIAL 10           // Initial congestion level on first failure

// Queue management and polling
#define SHM_QUEUE_REFRESH_INTERVAL 10       // Queue list refresh interval (loop iterations) - reduced from 200 for faster new queue detection
#define SHM_EMPTY_LOOP_THRESHOLD_SHORT 3    // Threshold for short timeout
#define SHM_EMPTY_LOOP_THRESHOLD_LONG 10    // Threshold for long timeout

// Timeout strategies (milliseconds)
#define SHM_TIMEOUT_SHORT_MS 5              // Short timeout (active receiving)
#define SHM_TIMEOUT_MEDIUM_MS 20            // Medium timeout
#define SHM_TIMEOUT_LONG_MS 50              // Long timeout (idle state)
#define SHM_TIMEOUT_IDLE_MS 100             // Idle wait when no queues available
#define SHM_IDLE_SLEEP_MS 10                // Sleep time when idle

// Adaptive polling thresholds
#define SHM_ADAPTIVE_THRESHOLD 50           // Threshold for adaptive timeout switch

// Node discovery and initialization
#define SHM_STARTUP_WAIT_MS 300             // Wait time for remote nodes to respond (queryRemoteServices)

namespace Nexus {
namespace rpc {

SharedMemoryTransportV3::SharedMemoryTransportV3()
    : initialized_(false)
    , notify_mechanism_(NotifyMechanism::CONDITION_VARIABLE)  // Must match declaration order in header
    , node_impl_(nullptr)
    , my_shm_ptr_(nullptr)
    , my_shm_fd_(-1)
    , my_shm_(nullptr)
    , receiving_(false)
{
}

SharedMemoryTransportV3::~SharedMemoryTransportV3() {
    stopReceiving();
    
    // Disconnect from all remote nodes
    {
        std::lock_guard<std::mutex> lock(connections_mutex_);
        for (auto& pair : remote_connections_) {
            if (pair.second.shm_ptr && pair.second.shm_ptr != MAP_FAILED) {
                munmap(pair.second.shm_ptr, sizeof(NodeSharedMemory));
            }
            if (pair.second.shm_fd >= 0) {
                close(pair.second.shm_fd);
            }
        }
        remote_connections_.clear();
    }
    
    // Unregister from registry
    if (initialized_) {
        registry_.unregisterNode(node_id_);
    }
    
    // Destroy my shared memory
    destroyMySharedMemory();
    
    NEXUS_DEBUG("SHM-V3") << "Node " << node_id_ << " destroyed";
}

bool SharedMemoryTransportV3::initialize(const std::string& node_id, const Config& config) {
    if (initialized_) {
        return true;
    }
    
    if (node_id.empty()) {
        NEXUS_ERROR("SHM-V3") << "Invalid node ID";
        return false;
    }
    
    // éªŒè¯é…ç½®
    if (config.max_inbound_queues > MAX_INBOUND_QUEUES) {
        NEXUS_ERROR("SHM-V3") << "Invalid config: max_inbound_queues (" 
                  << config.max_inbound_queues << ") exceeds limit (" 
                  << MAX_INBOUND_QUEUES << ")";
        return false;
    }
    
    node_id_ = node_id;
    config_ = config;
    notify_mechanism_ = config.notify_mechanism;  // ä¿å­˜é€šçŸ¥æœºåˆ¶é…ç½®
    
    // Initialize registry
    if (!registry_.initialize()) {
        NEXUS_ERROR("SHM-V3") << "Failed to initialize registry";
        return false;
    }
    
    // Generate unique shared memory name
    my_shm_name_ = generateShmName();
    
    // Create my shared memory
    if (!createMySharedMemory()) {
        NEXUS_ERROR("SHM-V3") << "Failed to create shared memory";
        return false;
    }
    
    // Register in registry
    if (!registry_.registerNode(node_id_, my_shm_name_)) {
        NEXUS_ERROR("SHM-V3") << "Failed to register node";
        destroyMySharedMemory();
        return false;
    }
    
    // ğŸ”§ ä¸¤é˜¶æ®µæäº¤ï¼šè®¾ç½®readyæ ‡å¿—
    my_shm_->header.ready.store(true, std::memory_order_release);
    
    initialized_ = true;
    
    const char* mechanism_name = "Unknown";
    if (notify_mechanism_ == NotifyMechanism::CONDITION_VARIABLE) {
        mechanism_name = "Condition Variable";
    } else if (notify_mechanism_ == NotifyMechanism::SEMAPHORE) {
        mechanism_name = "POSIX Semaphore";
    } else if (notify_mechanism_ == NotifyMechanism::SMART_POLLING) {
        mechanism_name = "Smart Polling";
    }
    
    NEXUS_DEBUG("SHM-V3") << "Node " << node_id_ << " initialized"
              << "\n  Notify mechanism: " << mechanism_name
              << "\n  Shared memory: " << my_shm_name_
              << "\n  Queue capacity: " << config_.queue_capacity
              << "\n  Max inbound queues: " << MAX_INBOUND_QUEUES
             ;
    
    return true;
}

bool SharedMemoryTransportV3::send(const std::string& dest_node_id, const uint8_t* data, size_t size) {
    if (!initialized_) {
        return false;
    }
    
    if (dest_node_id == node_id_) {
        return false;  // Don't send to self
    }
    
    // Fast path: check if already connected
    {
        std::lock_guard<std::mutex> lock(connections_mutex_);
        auto it = remote_connections_.find(dest_node_id);
        if (it != remote_connections_.end() && it->second.connected && it->second.my_queue) {
            InboundQueue* queue = it->second.my_queue;
            
            // ğŸ”§ æµæ§ï¼šæ£€æŸ¥æ‹¥å¡ç­‰çº§
            uint32_t congestion = queue->congestion_level.load(std::memory_order_relaxed);
            if (congestion > 0 && congestion <= SHM_CONGESTION_MAX) {
                // æ ¹æ®æ‹¥å¡ç­‰çº§è¿›è¡Œé€€é¿ (0-100 -> 0-1000Î¼s)
                int backoff_us = static_cast<int>(congestion) * SHM_BACKOFF_BASE_US;
                if (backoff_us > 0 && backoff_us <= SHM_BACKOFF_MAX_US) {
                    std::this_thread::sleep_for(std::chrono::microseconds(backoff_us));
                }
            }
            
            // å°è¯•å‘é€
            bool success = queue->queue.tryWrite(node_id_.c_str(), data, size);
            if (success) {
                stats_messages_sent_++;
                stats_bytes_sent_ += size;
                
                // ğŸ”§ é€šçŸ¥æ¥æ”¶ç«¯ï¼šæ ¹æ®é€šçŸ¥æœºåˆ¶é€‰æ‹©
                if (notify_mechanism_ == NotifyMechanism::SEMAPHORE) {
                    // ğŸ”§ Semaphoreæ¨¡å¼ï¼šæ‰¹é‡é€šçŸ¥ä¼˜åŒ–
                    // åªåœ¨pending_msgsä»0å˜1æ—¶æ‰sem_postï¼Œé¿å…è¿‡åº¦é€šçŸ¥
                    uint32_t prev = queue->pending_msgs.fetch_add(1, std::memory_order_release);
                    if (prev == 0) {
                        sem_post(&queue->notify_sem);  // åªæœ‰ç¬¬ä¸€æ¡æ¶ˆæ¯è§¦å‘é€šçŸ¥
                    }
                } else {
                    // ğŸ”§ Condition Variableæ¨¡å¼ï¼šæ‰¹é‡é€šçŸ¥ä¼˜åŒ–
                    // åªåœ¨pending_msgsä»0å˜1æ—¶æ‰signalï¼Œé¿å…è¿‡åº¦å”¤é†’
                    uint32_t prev = queue->pending_msgs.fetch_add(1, std::memory_order_release);
                    if (prev == 0) {
                        pthread_cond_signal(&queue->notify_cond);  // åªæœ‰ç¬¬ä¸€æ¡æ¶ˆæ¯è§¦å‘é€šçŸ¥
                    }
                    // æ³¨æ„ï¼šä¸éœ€è¦æŒæœ‰mutexæ¥signalï¼ˆPOSIXå…è®¸ï¼‰
                }
                
                // ğŸ”§ æµæ§ï¼šæˆåŠŸå‘é€ï¼Œé™ä½æ‹¥å¡ç­‰çº§
                if (congestion > 0) {
                    queue->congestion_level.fetch_sub(SHM_CONGESTION_DECREMENT, std::memory_order_relaxed);
                }
            } else {
                stats_messages_dropped_++;
                
                // ğŸ”§ æµæ§ï¼šå‘é€å¤±è´¥ï¼Œæé«˜æ‹¥å¡ç­‰çº§å’Œä¸¢åŒ…è®¡æ•°
                queue->drop_count.fetch_add(1, std::memory_order_relaxed);
                if (congestion < SHM_CONGESTION_MAX) {
                    queue->congestion_level.fetch_add(SHM_CONGESTION_INCREMENT, std::memory_order_relaxed);  // å¿«é€Ÿä¸Šå‡
                }
            }
            return success;
        }
    }
    
    // Slow path: establish connection first
    NEXUS_DEBUG("SHM-V3") << "[" << node_id_ << "] Not connected to " << dest_node_id 
                          << ", attempting lazy connection...";
    
    if (!connectToNode(dest_node_id)) {
        stats_messages_dropped_++;
        NEXUS_DEBUG("SHM-V3") << "[" << node_id_ << "] Failed to connect to " << dest_node_id;
        return false;
    }
    
    NEXUS_DEBUG("SHM-V3") << "[" << node_id_ << "] Successfully connected to " << dest_node_id;
    
    // Retry send after connection
    {
        std::lock_guard<std::mutex> lock(connections_mutex_);
        auto it = remote_connections_.find(dest_node_id);
        if (it != remote_connections_.end() && it->second.connected && it->second.my_queue) {
            InboundQueue* queue = it->second.my_queue;
            
            bool success = queue->queue.tryWrite(node_id_.c_str(), data, size);
            if (success) {
                stats_messages_sent_++;
                stats_bytes_sent_ += size;
                
                // ğŸ”§ é€šçŸ¥æ¥æ”¶ç«¯ï¼šæ ¹æ®é€šçŸ¥æœºåˆ¶é€‰æ‹©
                if (notify_mechanism_ == NotifyMechanism::SEMAPHORE) {
                    // ğŸ”§ Semaphoreæ¨¡å¼ï¼šæ‰¹é‡é€šçŸ¥ä¼˜åŒ–
                    uint32_t prev = queue->pending_msgs.fetch_add(1, std::memory_order_release);
                    if (prev == 0) {
                        sem_post(&queue->notify_sem);
                    }
                } else {
                    // ğŸ”§ Condition Variableæ¨¡å¼ï¼šæ‰¹é‡é€šçŸ¥ä¼˜åŒ–
                    uint32_t prev = queue->pending_msgs.fetch_add(1, std::memory_order_release);
                    if (prev == 0) {
                        pthread_cond_signal(&queue->notify_cond);
                    }
                }
            } else{
                stats_messages_dropped_++;
                queue->drop_count.fetch_add(1, std::memory_order_relaxed);
                queue->congestion_level.store(SHM_CONGESTION_INITIAL, std::memory_order_relaxed);  // åˆå§‹æ‹¥å¡
            }
            return success;
        }
    }
    
    stats_messages_dropped_++;
    return false;
}

int SharedMemoryTransportV3::broadcast(const uint8_t* data, size_t size) {
    if (!initialized_) {
        return 0;
    }
    
    // Get all nodes from registry
    std::vector<NodeInfo> nodes = registry_.getAllNodes();
    int sent_count = 0;
    
    NEXUS_DEBUG("SHM-V3") << "[" << node_id_ << "] Broadcasting to " << nodes.size() << " nodes in registry";
    
    for (const auto& node : nodes) {
        if (node.node_id == node_id_) {
            continue;  // Skip self
        }
        
        NEXUS_DEBUG("SHM-V3") << "[" << node_id_ << "] Broadcast attempt to " << node.node_id 
                              << " (active: " << node.active << ")";
        
        if (node.active && send(node.node_id, data, size)) {
            sent_count++;
            NEXUS_DEBUG("SHM-V3") << "[" << node_id_ << "] Broadcast to " << node.node_id << " SUCCESS";
        } else {
            NEXUS_DEBUG("SHM-V3") << "[" << node_id_ << "] Broadcast to " << node.node_id << " FAILED";
        }
    }
    
    return sent_count;
}

void SharedMemoryTransportV3::setReceiveCallback(ReceiveCallback callback) {
    receive_callback_ = callback;
}

void SharedMemoryTransportV3::startReceiving() {
    if (receiving_.load()) {
        return;
    }
    
    receiving_.store(true);
    
    // Start receive thread
    receive_thread_ = std::thread([this]() {
        receiveLoop();
    });
    
    // Start heartbeat thread
    heartbeat_thread_ = std::thread([this]() {
        heartbeatLoop();
    });
    
    NEXUS_DEBUG("SHM-V3") << "Started receiving threads for " << node_id_;
}

void SharedMemoryTransportV3::stopReceiving() {
    if (!receiving_.load()) {
        return;
    }
    
    receiving_.store(false);
    
    // ğŸ”§ Wake up all threads waiting on condition variables
    // This ensures receive threads exit immediately instead of waiting for timeout
    
    // 1. Wake up thread waiting for queue availability
    {
        std::lock_guard<std::mutex> lock(queue_wait_mutex_);
        queue_wait_cv_.notify_all();
    }
    
    // 2. Wake up threads waiting on queue-specific condition variables
    if (my_shm_) {
        for (uint32_t i = 0; i < MAX_INBOUND_QUEUES; ++i) {
            InboundQueue& q = my_shm_->queues[i];
            uint32_t flags = q.flags.load(std::memory_order_relaxed);
            if ((flags & 0x3) == 0x3) {  // Queue is active
                pthread_mutex_lock(&q.notify_mutex);
                pthread_cond_broadcast(&q.notify_cond);
                pthread_mutex_unlock(&q.notify_mutex);
            }
        }
    }
    
    if (receive_thread_.joinable()) {
        receive_thread_.join();
    }
    
    if (heartbeat_thread_.joinable()) {
        heartbeat_thread_.join();
    }
    
    NEXUS_DEBUG("SHM-V3") << "Stopped receiving threads for " << node_id_;
}

std::vector<std::string> SharedMemoryTransportV3::getLocalNodes() const {
    std::vector<std::string> node_ids;
    
    if (!initialized_) {
        return node_ids;
    }
    
    std::vector<NodeInfo> nodes = registry_.getAllNodes();
    for (const auto& node : nodes) {
        if (node.active) {
            node_ids.push_back(node.node_id);
        }
    }
    
    return node_ids;
}

bool SharedMemoryTransportV3::isLocalNode(const std::string& node_id) const {
    if (!initialized_) {
        return false;
    }
    
    return registry_.nodeExists(node_id);
}

int SharedMemoryTransportV3::getConnectionCount() const {
    std::lock_guard<std::mutex> lock(connections_mutex_);
    int count = 0;
    for (const auto& pair : remote_connections_) {
        if (pair.second.connected) {
            count++;
        }
    }
    return count;
}

void SharedMemoryTransportV3::warmupConnections() {
    if (!initialized_) {
        return;
    }
    
    std::vector<NodeInfo> nodes = registry_.getAllNodes();
    int connected = 0;
    
    for (const auto& node : nodes) {
        if (node.node_id != node_id_ && node.active) {
            if (connectToNode(node.node_id)) {
                connected++;
            }
        }
    }
    
    NEXUS_DEBUG("SHM-V3") << "Warmed up " << connected << " connections";
}

SharedMemoryTransportV3::TransportStats SharedMemoryTransportV3::getStats() const {
    TransportStats stats;
    stats.messages_sent = stats_messages_sent_.load();
    stats.messages_received = stats_messages_received_.load();
    stats.messages_dropped = stats_messages_dropped_.load();
    stats.bytes_sent = stats_bytes_sent_.load();
    stats.bytes_received = stats_bytes_received_.load();
    stats.active_connections = getConnectionCount();
    stats.inbound_queues = my_shm_ ? my_shm_->header.num_queues.load() : 0;
    
    // Calculate average queue depth
    stats.avg_queue_depth = 0.0;
    if (my_shm_) {
        uint32_t num_queues = my_shm_->header.num_queues.load();
        if (num_queues > 0) {
            uint64_t total_depth = 0;
            int active_queues = 0;
            for (uint32_t i = 0; i < num_queues && i < MAX_INBOUND_QUEUES; ++i) {
                InboundQueue& q = my_shm_->queues[i];
                if ((q.flags.load() & 0x3) == 0x3) {
                    total_depth += q.queue.size();
                    active_queues++;
                }
            }
            if (active_queues > 0) {
                stats.avg_queue_depth = static_cast<double>(total_depth) / active_queues;
            }
        }
    }
    
    return stats;
}

bool SharedMemoryTransportV3::cleanupOrphanedMemory() {
    NEXUS_DEBUG("SHM-V3") << "Cleaning up orphaned shared memory...";
    
    size_t cleaned_count = 0;
    size_t total_freed = 0;
    
    // è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»
    auto isProcessAlive = [](int32_t pid) -> bool {
        if (pid <= 0) {
            return false;  // æ— æ•ˆPID
        }
        
        // kill(pid, 0) ä¸å‘é€ä¿¡å·ï¼Œåªæ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
        if (kill(pid, 0) == 0) {
            return true;  // è¿›ç¨‹å­˜åœ¨ä¸”æœ‰æƒé™è®¿é—®
        }
        
        // ESRCH: è¿›ç¨‹ä¸å­˜åœ¨
        // EPERM: è¿›ç¨‹å­˜åœ¨ä½†æ— æƒé™ï¼ˆä¹Ÿç®—å­˜æ´»ï¼‰
        return errno != ESRCH;
    };
    
    // æ‰«æå…±äº«å†…å­˜ç›®å½•ï¼ŒæŸ¥æ‰¾librpc_node_*æ–‡ä»¶
    // QNX uses /dev/shmem instead of /dev/shm
    #ifdef __QNXNTO__
    const char* shm_dir = "/dev/shmem";
    #else
    const char* shm_dir = "/dev/shm";
    #endif
    
    DIR* dir = opendir(shm_dir);
    if (!dir) {
        NEXUS_ERROR("SHM-V3") << "Failed to open " << shm_dir << ": " << strerror(errno);
        return false;
    }
    
    struct dirent* entry;
    while ((entry = readdir(dir)) != nullptr) {
        std::string name = entry->d_name;
        
        // åªå¤„ç†librpc_node_*çš„å…±äº«å†…å­˜
        if (name.find("librpc_node_") != 0) {
            continue;
        }
        
        // å°è¯•æ‰“å¼€å…±äº«å†…å­˜
        std::string full_name = "/" + name;
        int fd = shm_open(full_name.c_str(), O_RDWR, 0);
        if (fd < 0) {
            continue;
        }
        
        // è·å–æ–‡ä»¶å¤§å°
        struct stat st;
        if (fstat(fd, &st) != 0) {
            close(fd);
            continue;
        }
        
        size_t shm_size = st.st_size;
        
        // æ˜ å°„å…±äº«å†…å­˜ä»¥æ£€æŸ¥header
        void* addr = mmap(nullptr, sizeof(NodeHeader), PROT_READ, MAP_SHARED, fd, 0);
        if (addr == MAP_FAILED) {
            close(fd);
            continue;
        }
        
        bool should_cleanup = false;
        std::string cleanup_reason;
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„V3èŠ‚ç‚¹å…±äº«å†…å­˜
        NodeHeader* header = static_cast<NodeHeader*>(addr);
        
        if (header->magic.load(std::memory_order_relaxed) == MAGIC) {
            // æ£€æŸ¥PIDæ˜¯å¦å­˜æ´»
            int32_t owner_pid = header->owner_pid.load(std::memory_order_relaxed);
            
            if (owner_pid > 0 && !isProcessAlive(owner_pid)) {
                should_cleanup = true;
                cleanup_reason = "owner process dead (PID: " + std::to_string(owner_pid) + ")";
            }
        } else {
            // ä¸æ˜¯æœ‰æ•ˆçš„V3å…±äº«å†…å­˜ï¼Œå¯èƒ½æ˜¯æ®‹ç•™æ–‡ä»¶
            should_cleanup = true;
            cleanup_reason = "invalid magic number";
        }
        
        munmap(addr, sizeof(NodeHeader));
        close(fd);
        
        if (should_cleanup) {
            if (shm_unlink(full_name.c_str()) == 0) {
                cleaned_count++;
                total_freed += shm_size;
                NEXUS_DEBUG("SHM-V3") << "âœ“ Cleaned: " << name 
                          << " (" << (shm_size / 1024 / 1024) << " MB) - " 
                          << cleanup_reason;
            } else {
                NEXUS_ERROR("SHM-V3") << "âœ— Failed to unlink " << name 
                          << ": " << strerror(errno);
            }
        }
    }
    
    closedir(dir);
    
    // æ¸…ç†registry
    if (SharedMemoryRegistry::cleanupOrphanedRegistry()) {
        NEXUS_DEBUG("SHM-V3") << "âœ“ Cleaned orphaned registry";
    }
    
    if (cleaned_count > 0) {
        NEXUS_DEBUG("SHM-V3") << "Cleanup complete: removed " << cleaned_count 
                  << " node(s), freed " << (total_freed / 1024 / 1024) << " MB";
    } else {
        NEXUS_DEBUG("SHM-V3") << "No orphaned nodes found";
    }
    
    return true;
}

int SharedMemoryTransportV3::getActiveNodeCount() {
    // Create temporary registry to query
    SharedMemoryRegistry temp_registry;
    if (!temp_registry.initialize()) {
        return -1;  // Registry doesn't exist
    }
    
    return temp_registry.getActiveNodeCount();
}

// Private helper methods

bool SharedMemoryTransportV3::createMySharedMemory() {
    // Create shared memory
    my_shm_fd_ = shm_open(my_shm_name_.c_str(), O_CREAT | O_EXCL | O_RDWR, 0666);
    if (my_shm_fd_ < 0) {
        // Maybe old instance exists, try to clean up
        shm_unlink(my_shm_name_.c_str());
        my_shm_fd_ = shm_open(my_shm_name_.c_str(), O_CREAT | O_EXCL | O_RDWR, 0666);
        if (my_shm_fd_ < 0) {
            NEXUS_ERROR("SHM-V3") << "Failed to create shared memory: " << strerror(errno);
            return false;
        }
    }
    
    // Set size
    size_t shm_size = sizeof(NodeSharedMemory);
    if (ftruncate(my_shm_fd_, shm_size) < 0) {
        NEXUS_ERROR("SHM-V3") << "Failed to set size: " << strerror(errno);
        close(my_shm_fd_);
        my_shm_fd_ = -1;
        shm_unlink(my_shm_name_.c_str());
        return false;
    }
    
    // Map memory
    // Note: MAP_NORESERVE may not be supported on QNX, use MAP_SHARED only
    #ifdef __QNXNTO__
    my_shm_ptr_ = mmap(nullptr, shm_size, PROT_READ | PROT_WRITE, 
                       MAP_SHARED, my_shm_fd_, 0);
    #else
    my_shm_ptr_ = mmap(nullptr, shm_size, PROT_READ | PROT_WRITE, 
                       MAP_SHARED | MAP_NORESERVE, my_shm_fd_, 0);
    #endif
    if (my_shm_ptr_ == MAP_FAILED) {
        NEXUS_ERROR("SHM-V3") << "Failed to map memory: " << strerror(errno);
        close(my_shm_fd_);
        my_shm_fd_ = -1;
        shm_unlink(my_shm_name_.c_str());
        return false;
    }
    
    my_shm_ = static_cast<NodeSharedMemory*>(my_shm_ptr_);
    
    // Initialize header
    my_shm_->header.magic.store(MAGIC);
    my_shm_->header.version.store(VERSION);
    my_shm_->header.num_queues.store(0);
    // Safe cast: max_inbound_queues is validated in initialize()
    my_shm_->header.max_queues.store(static_cast<uint32_t>(config_.max_inbound_queues));
    my_shm_->header.last_heartbeat.store(std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::steady_clock::now().time_since_epoch()).count());
    my_shm_->header.ready.store(false);  // ğŸ”§ åˆå§‹ä¸ºæœªå°±ç»ª
    my_shm_->header.owner_pid.store(getpid(), std::memory_order_release);  // ğŸ”§ è®°å½•è¿›ç¨‹PID
    
    // Initialize all queues
    for (size_t i = 0; i < MAX_INBOUND_QUEUES; ++i) {
        my_shm_->queues[i].flags.store(0);
        my_shm_->queues[i].sender_id[0] = '\0';
        my_shm_->queues[i].pending_msgs.store(0);  // ğŸ”§ å¾…å¤„ç†æ¶ˆæ¯è®¡æ•°åˆå§‹åŒ–
        // ğŸ”§ åˆå§‹åŒ–æµæ§å­—æ®µ
        my_shm_->queues[i].congestion_level.store(0);
        my_shm_->queues[i].drop_count.store(0);
    }
    
    size_t mb = shm_size / (1024 * 1024);
    NEXUS_DEBUG("SHM-V3") << "Created shared memory: " << my_shm_name_ 
              << " (" << mb << " MB, max_queues=" << config_.max_inbound_queues << ")";
    
    return true;
}

void SharedMemoryTransportV3::destroyMySharedMemory() {
    // ğŸ”§ æ³¨æ„ï¼špthreadå¯¹è±¡æ˜¯è·¨è¿›ç¨‹å…±äº«çš„ï¼Œä¸èƒ½éšæ„destroy
    // pthread_mutex/cond_destroyåªåº”è¯¥åœ¨æœ€åä¸€ä¸ªä½¿ç”¨è€…é€€å‡ºæ—¶è°ƒç”¨
    // è¿™é‡Œæˆ‘ä»¬åªæ˜¯unmapï¼Œè®©æ“ä½œç³»ç»Ÿåœ¨shmè¢«åˆ é™¤æ—¶æ¸…ç†
    
    if (my_shm_ptr_ && my_shm_ptr_ != MAP_FAILED) {
        munmap(my_shm_ptr_, sizeof(NodeSharedMemory));
        my_shm_ptr_ = nullptr;
        my_shm_ = nullptr;
    }
    
    if (my_shm_fd_ >= 0) {
        close(my_shm_fd_);
        my_shm_fd_ = -1;
    }
    
    if (!my_shm_name_.empty()) {
        shm_unlink(my_shm_name_.c_str());
        NEXUS_DEBUG("SHM-V3") << "Destroyed shared memory: " << my_shm_name_;
    }
}

bool SharedMemoryTransportV3::connectToNode(const std::string& target_node_id) {
    std::lock_guard<std::mutex> lock(connections_mutex_);
    
    // Check if already connected
    auto it = remote_connections_.find(target_node_id);
    if (it != remote_connections_.end() && it->second.connected) {
        return true;
    }
    
    // Get target node info from registry
    NodeInfo target_info;
    if (!registry_.findNode(target_node_id, target_info)) {
        NEXUS_ERROR("SHM-V3") << "Node not found in registry: " << target_node_id;
        return false;
    }
    
    // Create connection structure
    RemoteConnection conn;
    conn.node_id = target_node_id;
    conn.shm_name = target_info.shm_name;
    
    // Open target node's shared memory
    conn.shm_fd = shm_open(target_info.shm_name.c_str(), O_RDWR, 0666);
    if (conn.shm_fd < 0) {
        NEXUS_ERROR("SHM-V3") << "Failed to open remote shm " << target_info.shm_name 
                  << ": " << strerror(errno);
        return false;
    }
    
    // Map remote memory
    // Note: MAP_NORESERVE may not be supported on QNX, use MAP_SHARED only
    #ifdef __QNXNTO__
    conn.shm_ptr = mmap(nullptr, sizeof(NodeSharedMemory), PROT_READ | PROT_WRITE, 
                        MAP_SHARED, conn.shm_fd, 0);
    #else
    conn.shm_ptr = mmap(nullptr, sizeof(NodeSharedMemory), PROT_READ | PROT_WRITE, 
                        MAP_SHARED | MAP_NORESERVE, conn.shm_fd, 0);
    #endif
    if (conn.shm_ptr == MAP_FAILED) {
        NEXUS_ERROR("SHM-V3") << "Failed to map remote shm: " << strerror(errno);
        close(conn.shm_fd);
        return false;
    }
    
    NodeSharedMemory* remote_shm = static_cast<NodeSharedMemory*>(conn.shm_ptr);
    
    // Verify magic
    uint32_t magic = remote_shm->header.magic.load(std::memory_order_acquire);
    if (magic != MAGIC) {
        NEXUS_ERROR("SHM-V3") << "Invalid magic in remote shm: 0x" << std::hex << magic;
        munmap(conn.shm_ptr, sizeof(NodeSharedMemory));
        close(conn.shm_fd);
        return false;
    }
    
    // ğŸ”§ å¥åº·æ£€æŸ¥: éªŒè¯è¿œç¨‹è¿›ç¨‹æ˜¯å¦å­˜æ´»
    pid_t owner_pid = remote_shm->header.owner_pid.load(std::memory_order_acquire);
    if (owner_pid <= 0 || kill(owner_pid, 0) != 0) {
        NEXUS_WARN("SHM-V3") << "Remote node process is dead (pid=" << owner_pid 
                             << "), cleaning up stale shared memory: " << target_info.shm_name;
        munmap(conn.shm_ptr, sizeof(NodeSharedMemory));
        close(conn.shm_fd);
        // å°è¯•æ¸…ç†æ®‹ç•™çš„å…±äº«å†…å­˜æ–‡ä»¶
        shm_unlink(target_info.shm_name.c_str());
        // ä»registryä¸­åˆ é™¤å·²æ­»äº¡èŠ‚ç‚¹çš„entry
        registry_.unregisterNode(target_node_id);
        return false;
    }
    
    // ğŸ”§ ä¸¤é˜¶æ®µæäº¤ï¼šéªŒè¯èŠ‚ç‚¹æ˜¯å¦å®Œå…¨åˆå§‹åŒ–
    if (!remote_shm->header.ready.load(std::memory_order_acquire)) {
        NEXUS_ERROR("SHM-V3") << "Remote node not ready yet: " << target_node_id;
        munmap(conn.shm_ptr, sizeof(NodeSharedMemory));
        close(conn.shm_fd);
        return false;
    }
    
    // Find or create queue for me in target node's memory
    conn.my_queue = findOrCreateQueue(remote_shm, node_id_);
    if (!conn.my_queue) {
        NEXUS_ERROR("SHM-V3") << "Failed to create queue in remote node";
        munmap(conn.shm_ptr, sizeof(NodeSharedMemory));
        close(conn.shm_fd);
        return false;
    }
    
    conn.connected = true;
    
    remote_connections_[target_node_id] = conn;
    
    NEXUS_DEBUG("SHM-V3") << "Connected to node: " << target_node_id 
              << " (shm: " << target_info.shm_name << ")";
    
    return true;
}

void SharedMemoryTransportV3::disconnectFromNode(const std::string& target_node_id) {
    std::lock_guard<std::mutex> lock(connections_mutex_);
    
    auto it = remote_connections_.find(target_node_id);
    if (it == remote_connections_.end()) {
        return;
    }
    
    RemoteConnection& conn = it->second;
    
    if (conn.shm_ptr && conn.shm_ptr != MAP_FAILED) {
        munmap(conn.shm_ptr, sizeof(NodeSharedMemory));
    }
    
    if (conn.shm_fd >= 0) {
        close(conn.shm_fd);
    }
    
    remote_connections_.erase(it);
    
    NEXUS_DEBUG("SHM-V3") << "Disconnected from node: " << target_node_id;
}

SharedMemoryTransportV3::InboundQueue* SharedMemoryTransportV3::findOrCreateQueue(
    NodeSharedMemory* remote_shm, const std::string& sender_id) {
    // First, try to find existing queue
    uint32_t num_queues = remote_shm->header.num_queues.load();
    for (uint32_t i = 0; i < num_queues && i < MAX_INBOUND_QUEUES; ++i) {
        InboundQueue& q = remote_shm->queues[i];
        if ((q.flags.load() & 0x1) && strcmp(q.sender_id, sender_id.c_str()) == 0) {
            return &q;
        }
    }
    
    // Not found, create new queue
    uint32_t max_queues = remote_shm->header.max_queues.load();
    if (num_queues >= max_queues) {
        NEXUS_ERROR("SHM-V3") << "Remote node queue limit reached (" << max_queues << ")";
        return nullptr;
    }
    
    // Find free slot
    for (size_t i = 0; i < MAX_INBOUND_QUEUES; ++i) {
        InboundQueue& q = remote_shm->queues[i];
        uint32_t expected = 0;
        if (q.flags.compare_exchange_strong(expected, 0x3)) {  // Try to claim: valid | active
            // Successfully claimed this slot
            strncpy(q.sender_id, sender_id.c_str(), sizeof(q.sender_id) - 1);
            q.sender_id[sizeof(q.sender_id) - 1] = '\0';
            
            // ğŸ”§ æ ¹æ®é€šçŸ¥æœºåˆ¶åˆå§‹åŒ–ç›¸åº”èµ„æº
            if (notify_mechanism_ == NotifyMechanism::SEMAPHORE) {
                // ğŸ”§ Semaphoreæ¨¡å¼ï¼šåˆå§‹åŒ–è¿›ç¨‹é—´å…±äº«ä¿¡å·é‡
                if (sem_init(&q.notify_sem, 1, 0) != 0) {
                    NEXUS_ERROR("SHM-V3") << "sem_init failed: " << strerror(errno);
                    q.flags.store(0);  // å›æ»š
                    return nullptr;
                }
                NEXUS_DEBUG("SHM-V3") << "Created queue with Semaphore for sender: " << sender_id;
            } else {
                // Condition Variableæ¨¡å¼ï¼šåˆå§‹åŒ–pthreadå¯¹è±¡
                pthread_mutexattr_t mattr;
                pthread_mutexattr_init(&mattr);
                pthread_mutexattr_setpshared(&mattr, PTHREAD_PROCESS_SHARED);
                pthread_mutex_init(&q.notify_mutex, &mattr);
                pthread_mutexattr_destroy(&mattr);
                
                pthread_condattr_t cattr;
                pthread_condattr_init(&cattr);
                pthread_condattr_setpshared(&cattr, PTHREAD_PROCESS_SHARED);
                pthread_cond_init(&q.notify_cond, &cattr);
                pthread_condattr_destroy(&cattr);
                
                q.pending_msgs.store(0);
                
                NEXUS_DEBUG("SHM-V3") << "Created queue in remote node for sender: " << sender_id 
                          << " (using Condition Variable)";
                
                // ğŸ”§ ç«‹å³é€šçŸ¥è¿œç¨‹èŠ‚ç‚¹æœ‰æ–°é˜Ÿåˆ—ï¼šé€šè¿‡æ–°queueçš„condition variableå‘é€ä¿¡å·
                // è¿™ä¼šå”¤é†’è¿œç¨‹èŠ‚ç‚¹çš„æ¥æ”¶å¾ªç¯ï¼Œä½¿å…¶ç«‹å³åˆ·æ–°é˜Ÿåˆ—åˆ—è¡¨ï¼Œæ¶ˆé™¤å»¶è¿Ÿ
                pthread_mutex_lock(&q.notify_mutex);
                pthread_cond_signal(&q.notify_cond);
                pthread_mutex_unlock(&q.notify_mutex);
            }
            
            remote_shm->header.num_queues.fetch_add(1);
            
            NEXUS_DEBUG("SHM-V3") << "Created queue in remote node, num_queues now: " 
                      << remote_shm->header.num_queues.load();
            
            return &q;
        }
    }
    
    return nullptr;
}

void SharedMemoryTransportV3::receiveLoop() {
    if (notify_mechanism_ == NotifyMechanism::SEMAPHORE) {
        receiveLoop_Semaphore();
    } else {
        receiveLoop_CV();
    }
}

// Condition Variableæ¨¡å¼çš„æ¥æ”¶å¾ªç¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
void SharedMemoryTransportV3::receiveLoop_CV() {
    NEXUS_DEBUG("SHM-V3") << "Receive loop started for " << node_id_ << " (Condition Variable mode - optimized)";
    
    static constexpr size_t MESSAGE_SIZE = 2048;
    uint8_t buffer[MESSAGE_SIZE];
    
    // ç¼“å­˜æ´»è·ƒé˜Ÿåˆ—åˆ—è¡¨ï¼Œå‡å°‘éå†å¼€é”€
    std::vector<InboundQueue*> active_queues;
    uint32_t cached_num_queues = 0;
    int queue_refresh_counter = 0;
    
    // è‡ªé€‚åº”è¶…æ—¶ï¼šæ ¹æ®æ¶ˆæ¯æµé‡åŠ¨æ€è°ƒæ•´
    int consecutive_empty_loops = 0;
    
    while (receiving_.load()) {
        if (!my_shm_) {
            // ğŸ”§ Wait for shared memory - use longer sleep since this is rare
            std::this_thread::sleep_for(std::chrono::milliseconds(50));
            continue;
        }
        
        // âœ… ä¼˜åŒ–7: å‡å°‘é˜Ÿåˆ—åˆ·æ–°æ£€æŸ¥çš„å¼€é”€
        // åªåœ¨å¿…è¦æ—¶æ‰æ£€æŸ¥ num_queuesï¼ˆå‡å°‘ atomic loadï¼‰
        queue_refresh_counter++;
        
        // ğŸ”§ å…³é”®ä¼˜åŒ–ï¼šç«‹å³æ£€æµ‹num_queueså˜åŒ–ï¼Œæ— éœ€ç­‰å¾…è®¡æ•°å™¨
        uint32_t current_num_queues = my_shm_->header.num_queues.load(std::memory_order_relaxed);
        
        // å»¶é•¿åˆ·æ–°é—´éš”ï¼ˆé™ä½æ£€æŸ¥é¢‘ç‡ï¼‰ï¼Œä½†num_queueså˜åŒ–æ—¶ç«‹å³åˆ·æ–°
        bool need_refresh = (current_num_queues != cached_num_queues) ||
                           (queue_refresh_counter >= SHM_QUEUE_REFRESH_INTERVAL) || 
                           active_queues.empty();
        
        if (need_refresh) {
            if (current_num_queues != cached_num_queues || active_queues.empty()) {
                active_queues.clear();
                active_queues.reserve(current_num_queues);  // âœ… é¢„ç•™ç©ºé—´é¿å…realloc
                
                for (uint32_t i = 0; i < MAX_INBOUND_QUEUES; ++i) {
                    InboundQueue& q = my_shm_->queues[i];
                    uint32_t flags = q.flags.load(std::memory_order_relaxed);
                    if ((flags & 0x3) == 0x3) {
                        active_queues.push_back(&q);
                    }
                }
                cached_num_queues = current_num_queues;
                
                // ğŸ”§ å¦‚æœæ£€æµ‹åˆ°æ–°é˜Ÿåˆ—ï¼Œé€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹
                if (!active_queues.empty() && !has_active_queues_.load(std::memory_order_relaxed)) {
                    has_active_queues_.store(true, std::memory_order_release);
                    queue_wait_cv_.notify_one();
                }
            }
            queue_refresh_counter = 0;
        }
        
        if (active_queues.empty()) {
            // ğŸ”§ No queues available - use condition variable to wait efficiently
            // This avoids busy-wait and reduces CPU to 0% when idle
            has_active_queues_.store(false, std::memory_order_release);
            
            std::unique_lock<std::mutex> lock(queue_wait_mutex_);
            queue_wait_cv_.wait_for(lock, std::chrono::milliseconds(SHM_TIMEOUT_IDLE_MS), [this]() {
                return !receiving_.load() || has_active_queues_.load();
            });
            continue;
        }
        
        // Mark that we have active queues
        has_active_queues_.store(true, std::memory_order_relaxed);
        
        // ğŸ”§ æ­¥éª¤1ï¼šå¿«é€Ÿå¤„ç†æ‰€æœ‰é˜Ÿåˆ—çš„æ¶ˆæ¯ï¼ˆæ‰¹é‡å¤„ç†å‡å°‘atomicæ“ä½œï¼‰
        bool has_messages = false;
        
        for (auto* q : active_queues) {
            // âœ… ä¼˜åŒ–1: å…ˆæ£€æŸ¥pending_msgsï¼Œé¿å…æ— æ¶ˆæ¯æ—¶çš„flagsæ£€æŸ¥å’Œå¾ªç¯
            uint32_t pending = q->pending_msgs.load(std::memory_order_acquire);
            if (pending == 0) {
                continue;  // é˜Ÿåˆ—æ— æ¶ˆæ¯ï¼Œè·³è¿‡
            }
            
            // å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯é˜Ÿåˆ—ä»ç„¶æœ‰æ•ˆ
            uint32_t flags = q->flags.load(std::memory_order_relaxed);
            if ((flags & 0x3) != 0x3) {
                continue;
            }
            
            // ğŸ”§ æ‰¹é‡å¤„ç†è¯¥é˜Ÿåˆ—çš„æ‰€æœ‰æ¶ˆæ¯
            int processed = 0;
            while (true) {
                char from_node[64];
                size_t msg_size = MESSAGE_SIZE;
                
                if (!q->queue.tryRead(from_node, buffer, msg_size)) {
                    break;  // é˜Ÿåˆ—ç©ºäº†
                }
                
                // âœ… ä¼˜åŒ–2: æ‰¹é‡æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å°‘cache line bouncingï¼‰
                processed++;
                has_messages = true;
                
                if (receive_callback_) {
                    NEXUS_DEBUG("SHM-V3") << "Received message from " << from_node 
                              << " (" << msg_size << " bytes)";
                    receive_callback_(buffer, msg_size, from_node);
                }
            }
            
            // âœ… ä¼˜åŒ–3: æ‰¹é‡æ›´æ–°ç»Ÿè®¡å’Œpendingè®¡æ•°ï¼ˆå‡å°‘atomicæ“ä½œï¼‰
            if (processed > 0) {
                stats_messages_received_ += processed;
                // stats_bytes_received_ åœ¨è¿™é‡Œæ— æ³•å‡†ç¡®ç´¯åŠ ï¼Œéœ€è¦åœ¨è¯»å–æ—¶ç´¯åŠ 
                q->pending_msgs.fetch_sub(processed, std::memory_order_release);
            }
        }
        
        // ğŸ”§ æ­¥éª¤2ï¼šå¦‚æœæ²¡æœ‰æ¶ˆæ¯ï¼Œä½¿ç”¨condition variableç­‰å¾…
        if (!has_messages && !active_queues.empty()) {
            consecutive_empty_loops++;
            
            // âœ… ä¼˜åŒ–4: æ›´æ¿€è¿›çš„è‡ªé€‚åº”è¶…æ—¶ç­–ç•¥
            // æ— æ¶ˆæ¯æ—¶å¿«é€Ÿè¿›å…¥é•¿è¶…æ—¶ï¼Œå‡å°‘é¢‘ç¹çš„CVæ“ä½œ
            int timeout_ms = (consecutive_empty_loops > SHM_EMPTY_LOOP_THRESHOLD_LONG) ? SHM_TIMEOUT_LONG_MS : 
                            (consecutive_empty_loops > SHM_EMPTY_LOOP_THRESHOLD_SHORT) ? SHM_TIMEOUT_MEDIUM_MS : SHM_TIMEOUT_SHORT_MS;
            
            // âœ… ä¼˜åŒ–5: ä½¿ç”¨æœ€ç¹å¿™çš„é˜Ÿåˆ—è¿›è¡Œç­‰å¾…ï¼ˆè€Œä¸æ˜¯æ€»æ˜¯ç¬¬ä¸€ä¸ªï¼‰
            // é€‰æ‹©pending_msgsæœ€å¤šçš„é˜Ÿåˆ—ï¼Œæé«˜è¢«å”¤é†’çš„æ¦‚ç‡
            InboundQueue* wait_queue = active_queues[0];
            uint32_t max_pending = 0;
            for (auto* q : active_queues) {
                uint32_t pending = q->pending_msgs.load(std::memory_order_relaxed);
                if (pending > max_pending) {
                    max_pending = pending;
                    wait_queue = q;
                }
            }
            
            // å¦‚æœæ‰€æœ‰é˜Ÿåˆ—éƒ½æ²¡æœ‰pendingæ¶ˆæ¯ï¼Œæ‰è¿›å…¥ç­‰å¾…
            if (max_pending == 0) {
                pthread_mutex_lock(&wait_queue->notify_mutex);
                
                // ğŸ”§ å†æ¬¡å¿«é€Ÿæ£€æŸ¥pendingï¼ˆåŒé‡æ£€æŸ¥é¿å…ä¿¡å·ä¸¢å¤±ï¼‰
                if (wait_queue->pending_msgs.load(std::memory_order_acquire) == 0) {
                    struct timespec ts;
                    clock_gettime(CLOCK_REALTIME, &ts);
                    
                    // âœ… ä¼˜åŒ–6: ä¼˜åŒ–æ—¶é—´è®¡ç®—ï¼Œé¿å…å¤šæ¬¡é™¤æ³•
                    long nsec_add = (long)timeout_ms * 1000000L;
                    ts.tv_sec += nsec_add / 1000000000L;
                    ts.tv_nsec += nsec_add % 1000000000L;
                    if (ts.tv_nsec >= 1000000000L) {
                        ts.tv_sec++;
                        ts.tv_nsec -= 1000000000L;
                    }
                    
                    pthread_cond_timedwait(&wait_queue->notify_cond, &wait_queue->notify_mutex, &ts);
                }
                
                pthread_mutex_unlock(&wait_queue->notify_mutex);
            }
        } else {
            // ğŸ”§ æœ‰æ¶ˆæ¯æ—¶é‡ç½®è®¡æ•°å™¨ï¼Œä¿æŒçŸ­è¶…æ—¶ä»¥é™ä½å»¶è¿Ÿ
            consecutive_empty_loops = 0;
        }
    }
    
    NEXUS_DEBUG("SHM-V3") << "Receive loop stopped for " << node_id_ << " (CV mode)";
}

// ğŸ”§ Semaphoreæ¨¡å¼çš„æ¥æ”¶å¾ªç¯ï¼ˆä¼˜åŒ–ç‰ˆï¼šçœŸæ­£åˆ©ç”¨sem_timedwaité˜»å¡ç­‰å¾…ï¼‰
void SharedMemoryTransportV3::receiveLoop_Semaphore() {
    NEXUS_DEBUG("SHM-V3") << "Receive loop started for " << node_id_ << " (Semaphore mode - optimized)";
    
    static constexpr size_t MESSAGE_SIZE = 2048;
    uint8_t buffer[MESSAGE_SIZE];
    
    // ğŸ”§ ç¼“å­˜æ´»è·ƒé˜Ÿåˆ—åˆ—è¡¨ï¼Œå®šæœŸæ›´æ–°ä»¥é™ä½å¼€é”€
    std::vector<InboundQueue*> active_queues;
    uint32_t cached_num_queues = 0;  // ç¼“å­˜num_queuesç”¨äºæ£€æµ‹å˜åŒ–
    int queue_refresh_counter = 0;
    const int QUEUE_REFRESH_INTERVAL = SHM_QUEUE_REFRESH_INTERVAL;  // å®šæœŸåˆ·æ–°é˜Ÿåˆ—åˆ—è¡¨
    
    // ğŸ”§ è‡ªé€‚åº”è¶…æ—¶ï¼šæœ‰æ¶ˆæ¯æ—¶ä½¿ç”¨çŸ­è¶…æ—¶ï¼Œæ— æ¶ˆæ¯æ—¶ä½¿ç”¨é•¿è¶…æ—¶
    int consecutive_empty_loops = 0;
    const int ADAPTIVE_THRESHOLD = SHM_ADAPTIVE_THRESHOLD;  // ç©ºå¾ªç¯é˜ˆå€¼ååˆ‡æ¢åˆ°é•¿è¶…æ—¶
    
    while (receiving_.load()) {
        if (!my_shm_) {
            std::this_thread::sleep_for(std::chrono::milliseconds(SHM_IDLE_SLEEP_MS));
            continue;
        }
        
        // ğŸ”§ æ£€æµ‹é˜Ÿåˆ—å˜åŒ–ï¼šnum_queueså˜åŒ–æˆ–å®šæœŸåˆ·æ–°
        uint32_t current_num_queues = my_shm_->header.num_queues.load(std::memory_order_relaxed);
        queue_refresh_counter++;
        
        if (current_num_queues != cached_num_queues || 
            queue_refresh_counter >= QUEUE_REFRESH_INTERVAL || 
            active_queues.empty()) {
            
            active_queues.clear();
            for (uint32_t i = 0; i < MAX_INBOUND_QUEUES; ++i) {
                InboundQueue& q = my_shm_->queues[i];
                uint32_t flags = q.flags.load(std::memory_order_relaxed);
                if ((flags & 0x3) == 0x3) {
                    active_queues.push_back(&q);
                }
            }
            cached_num_queues = current_num_queues;
            queue_refresh_counter = 0;
        }
        
        if (active_queues.empty()) {
            std::this_thread::sleep_for(std::chrono::milliseconds(SHM_IDLE_SLEEP_MS));
            continue;
        }
        
        // ğŸ”§ æ­¥éª¤1ï¼šå¿«é€Ÿè½®è¯¢æ‰€æœ‰é˜Ÿåˆ—ï¼ˆæ— é˜»å¡ï¼‰
        bool has_messages = false;
        for (auto* q : active_queues) {
            // ğŸ”§ å®‰å…¨æ£€æŸ¥ï¼šæ¯æ¬¡è®¿é—®å‰éªŒè¯é˜Ÿåˆ—ä»ç„¶æœ‰æ•ˆ
            uint32_t flags = q->flags.load(std::memory_order_relaxed);
            if ((flags & 0x3) != 0x3) {
                continue;  // é˜Ÿåˆ—å·²å¤±æ•ˆï¼Œè·³è¿‡
            }
            
            int processed = 0;
            while (true) {
                char from_node[64];
                size_t msg_size = MESSAGE_SIZE;
                
                if (!q->queue.tryRead(from_node, buffer, msg_size)) {
                    break;  // é˜Ÿåˆ—ç©ºäº†
                }
                
                stats_messages_received_++;
                stats_bytes_received_ += msg_size;
                has_messages = true;
                processed++;
                
                if (receive_callback_) {
                    receive_callback_(buffer, msg_size, from_node);
                }
            }
            
            // ğŸ”§ å¤„ç†å®Œæ¶ˆæ¯åï¼Œå‡å°‘pending_msgsè®¡æ•°
            if (processed > 0) {
                q->pending_msgs.fetch_sub(processed, std::memory_order_release);
            }
        }
        
        // ğŸ”§ æ­¥éª¤2ï¼šå¦‚æœæ²¡æœ‰æ¶ˆæ¯ï¼Œä½¿ç”¨sem_timedwaité˜»å¡ç­‰å¾…
        if (!has_messages && !active_queues.empty()) {
            consecutive_empty_loops++;
            
            // ğŸ”§ è‡ªé€‚åº”è¶…æ—¶ï¼šç©ºé—²æ—¶é•¿è¶…æ—¶ï¼Œç¹å¿™æ—¶çŸ­è¶…æ—¶
            int timeout_ms = (consecutive_empty_loops > ADAPTIVE_THRESHOLD) ? SHM_TIMEOUT_LONG_MS : SHM_TIMEOUT_SHORT_MS;
            
            struct timespec timeout;
            clock_gettime(CLOCK_REALTIME, &timeout);
            long timeout_ns = timeout_ms * 1000000L;
            timeout.tv_nsec += timeout_ns;
            if (timeout.tv_nsec >= 1000000000) {
                timeout.tv_sec++;
                timeout.tv_nsec -= 1000000000;
            }
            
            // ğŸ”§ ç­‰å¾…ä»»æ„é˜Ÿåˆ—çš„ä¿¡å·é‡ï¼ˆå°è¯•æ‰€æœ‰é˜Ÿåˆ—ç›´åˆ°æˆåŠŸæˆ–è¶…æ—¶ï¼‰
            bool got_signal = false;
            for (auto* q : active_queues) {
                if (sem_trywait(&q->notify_sem) == 0) {
                    got_signal = true;
                    break;
                }
            }
            
            // å¦‚æœæ²¡æœ‰ç«‹å³å¯ç”¨çš„ä¿¡å·ï¼Œç­‰å¾…ç¬¬ä¸€ä¸ªé˜Ÿåˆ—
            if (!got_signal) {
                sem_timedwait(&active_queues[0]->notify_sem, &timeout);
            }
        } else {
            // æœ‰æ¶ˆæ¯æ—¶é‡ç½®ç©ºå¾ªç¯è®¡æ•°
            consecutive_empty_loops = 0;
        }
    }
    
    NEXUS_DEBUG("SHM-V3") << "Receive loop stopped for " << node_id_ << " (Semaphore mode)";
}

void SharedMemoryTransportV3::heartbeatLoop() {
    NEXUS_DEBUG("SHM-V3") << "Heartbeat loop started for " << node_id_;
    
    while (receiving_.load()) {
        // Update my heartbeat in registry
        registry_.updateHeartbeat(node_id_);
        
        // Update my heartbeat in my shared memory
        if (my_shm_) {
            auto now = std::chrono::steady_clock::now();
            auto ms = std::chrono::duration_cast<std::chrono::milliseconds>(now.time_since_epoch());
            my_shm_->header.last_heartbeat.store(ms.count());
        }
        
        // Get nodes before cleanup (for detecting removed nodes)
        std::vector<NodeInfo> nodes_before;
        if (node_impl_) {
            nodes_before = registry_.getAllNodes();
        }
        
        // Clean up stale nodes from registry
        int cleaned = registry_.cleanupStaleNodes(NODE_TIMEOUT_MS);
        
        // Notify NodeImpl about removed nodes (trigger NODE_LEFT events)
        if (cleaned > 0 && node_impl_) {
            auto nodes_after = registry_.getAllNodes();
            
            // Find which nodes were removed
            for (const auto& node : nodes_before) {
                // Skip self
                if (node.node_id == node_id_) {
                    continue;
                }
                
                // Check if node still exists
                bool found = false;
                for (const auto& n : nodes_after) {
                    if (n.node_id == node.node_id) {
                        found = true;
                        break;
                    }
                }
                
                // Node was removed - trigger NODE_LEFT event
                if (!found) {
                    NEXUS_DEBUG("SHM-V3") << "Heartbeat timeout detected for node: " 
                              << node.node_id << ", triggering NODE_LEFT event";
                    node_impl_->handleNodeEvent(node.node_id, false);
                }
            }
        }
        
        // Clean up stale inbound queues
        cleanupStaleQueues();
        
        std::this_thread::sleep_for(std::chrono::milliseconds(HEARTBEAT_INTERVAL_MS));
    }
    
    NEXUS_DEBUG("SHM-V3") << "Heartbeat loop stopped for " << node_id_;
}

void SharedMemoryTransportV3::cleanupStaleQueues() {
    if (!my_shm_) {
        return;
    }
    
    // ğŸ”§ CRITICAL: Do NOT recycle inbound queues here!
    // Inbound queues are in OUR shared memory, used to receive messages.
    // Even if the sender node dies, we shouldn't touch these queues because:
    // 1. Our receive thread might still be accessing them
    // 2. There could be pending messages to process
    // 3. Race conditions can cause memory corruption
    //
    // Queue cleanup should only happen when:
    // - This node is shutting down (in destructor)
    // - We explicitly disconnect from a remote node
    //
    // For now, leave queues alone - they'll be cleaned up during node shutdown
    // TODO: Implement safer queue recycling with proper synchronization
}

std::string SharedMemoryTransportV3::generateShmName() {
    std::ostringstream oss;
    oss << "/librpc_node_" << getpid() << "_" << std::hex << std::setfill('0') 
        << std::setw(8) << (std::hash<std::string>{}(node_id_) & 0xFFFFFFFF);
    return oss.str();
}

} // namespace rpc
} // namespace Nexus
